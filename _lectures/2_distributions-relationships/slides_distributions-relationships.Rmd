---
title: "Distributions and Relationships"
subtitle: "IQA Lecture 2"
author: "Charles Lanfear"
date: "19 Oct 2022<br>Updated: `r gsub(' 0', ' ', format(Sys.Date(), format='%d %b %Y'))`"
output:
  xaringan::moon_reader:
    css: "../assets/cam-css.css"
    lib_dir: libs
    nature:
      highlightStyle: tomorrow-night-bright
      highlightLines: true
      countIncrementalSlides: false
      beforeInit: "../assets/cam_macros.js"
      titleSlideClass: ["center","top"]
---

```{r setup, purl=FALSE}
#| include: false
options(width = 68)
knitr::opts_chunk$set(eval=TRUE, echo=TRUE, message=TRUE, warning=TRUE, dev = "svg")
```



# Today

* News items:
   * Two assessments
      * *Light* data analysis and interpretation
      * One week to complete
   * [Jing's Office Hours](https://us05web.zoom.us/j/84826817691?pwd=cjFnQjBJY1BkOUxvRnBrQy9KbExNQT09): Friday, 12:30-13:30
      * Also by appointment
   * Reschedule Nov 16th to Monday Nov 14th
     * Tentative: 4 PM

* Topics for today:
   
   * Subsetting with logical expressions
   * Pipes 
   * Creating and modifying variables
   * Distributions
      * Tabulations and Cross-Tabulations
      * Summarizing data
      * Correlations

---
class: inverse

# Logical Expressions

&nbsp;

&nbsp;

![:width 50%](img/spock.gif)

---

# Indexing

Last week we subset or indexed data like so:

```{r}
USArrests[c("California", "Arkansas"), 2:3]
```

This is indexing by **name** or **position**

---

# Indexing by Expression

We can also index using expressions—logical *tests*.

```{r}
USArrests[USArrests$Murder > 15, ]
```

--

What does this give us?


---

# How Expressions Work

What does `USArrests$Murder > 15` actually do? 

--

```{r}
USArrests$Murder > 15
```

--

It returns a vector of `TRUE` or `FALSE` values.

When used with the subset operator (`[]`), elements for which a `TRUE` is given are returned while those corresponding to `FALSE` are dropped.

--

```{r}
c(1,2,3,4)[c(TRUE, FALSE, TRUE, FALSE)]
```


---

# Logical Operators

We used `>` for testing "greater than": `USArrests$Murder > 15`.

--

There are many other [logical operators](http://www.statmethods.net/management/operators.html):

--
* `==`: equal to

--
* `!=`: not equal to

--
* `>`, `>=`, `<`, `<=`: less than, less than or equal to, etc.

--
* `%in%`: used with checking equal to one of several values

--

Or we can combine multiple logical conditions:

* `&`: both conditions need to hold (AND)
--

* `|`: at least one condition needs to hold (OR)
--

* `!`: inverts a logical condition (`TRUE` becomes `FALSE`, `FALSE` becomes `TRUE`)

--

Logical operators are one of the foundations of programming. You should experiment with these to become familiar with how they work!

---

# And: `&`

![:width 50%](img/murder_and_assault.svg)

```{r}
USArrests[USArrests$Murder > 15 & USArrests$Assault > 300, ]
```



---

# Or: `|`

![:width 50%](img/murder_or_assault.svg)

```{r}
USArrests[USArrests$Murder > 15 | USArrests$Assault > 300, ]
```


---

# Sidenote: Missing Values

Missing values are coded as `NA` entries without quotes:

```{r}
vector_w_missing <- c(1, 2, NA, 4, 5, 6, NA)
```

--

Even one `NA` "poisons the well": You'll get `NA` out of your calculations unless you remove them manually or use the extra argument `na.rm = TRUE` in some functions:

```{r}
mean(vector_w_missing)
```

--

We can take missings (`NA`) and remove (`rm`) them:

```{r}
mean(vector_w_missing, na.rm=TRUE)
```

---
# Finding Missing Values

**WARNING:** You can't test for missing values by seeing if they "equal" (`==`) `NA`:

```{r}
vector_w_missing == NA
```

--

But you can use the `is.na()` function:

```{r}
is.na(vector_w_missing)
```

--

We can use subsetting to get the equivalent of `na.rm=TRUE`:

```{r}
mean(vector_w_missing[!is.na(vector_w_missing)]) #<<
```


.footnote[
`!` *reverses* a logical condition. Read the above as "subset to *not* `NA`"
]

---
class: inverse

# `{tidyverse}`

&nbsp;

![:width 40%](img/tidyverse.svg)

---

# Installing `{tidyverse}`

We're going to practice loading files and manipulating data.

--

We will use a packages called `{readr}` and `{dplyr}` to do this neatly.

These packages are part of the [Tidyverse](http://tidyverse.org/) family of R packages

* These packages make using R *much easier*

--

If you have not already installed the tidyverse, type, in the console: `install.packages("tidyverse")`

--

This will install a *large* number of R packages we will use throughout the term, including `{readr}`, `{ggplot2}`, and `{dplyr}`.

---

# Loading Packages

```{r}
library(readr)
library(ggplot2)
library(dplyr)
```

---

# Wait, was that an error?

When you load packages in R that have functions sharing the same name as functions you already have, the more recently loaded functions overwrite the previous ones ("masks them").

--

This **message** is just letting you know that.

--

Sometimes you may get a **warning message** when loading packages---usually because you aren't running the latest version of R:

```
Warning message:
package `dplyr' was built under R version 4.2.2
```

*Update R* to get rid of these!

---
class: inverse
# Importing and Exporting Data

&nbsp;

![:width 40%](img/readr.svg)

---

# Delimited Text Files

One of the most common ways for data to be stored is in a *delimited* text file, e.g. comma-separated values (**.csv**) or tab-separated values (**.tsv**). Here is **.csv** data:

```
"Id","Offense","Sex","Month"
101,"Battery","Male",1,
101,"Battery","Male",1,
101,"Robbery","Male",1,
101,"Battery","Male",2,
101,"Robbery","Male",2,
101,"Homicide","Male",3,
103,"Robbery","Female",1,
103,"Robbery","Female",3,
103,"Battery","Female",4,
```

---
# `{readr}`

R has a variety of built-in functions for importing delimited text, like `read.table()` and `read.csv()`.

I recommend using the versions in the `{readr}` package instead: `read_csv()`, `read_tsv()`, and `read_delim()`:

`{readr}` function features:

* Faster!
* A *little* smarter about dates and times
* Handy function `problems()` you can run if there are errors
* Loading bars for large files

---

# `{readr}` Importing Example

Let's use `read_csv()` from `{readr}` to import some community crime data based on those in yesterday's CRM lecture

.small[
```{r}
communities <- 
  read_csv(
    "https://clanfear.github.io/ioc_iqa/_data/communities.csv"
    )
```
]

---
class: inverse

# `{dplyr}`

&nbsp;

![:width 60%](img/dplyr.svg)

---

# Check Out Shootings

`{dplyr}` gives us access to the handy `glimpse()` for inspecting dataframes.

.text-62[
```{r}
glimpse(communities)
```
]

---

# But first, pipes!

`{dplyr}` and rest of the Tidyverse are built around using pipe operators (`|>`)

Instead of nesting functions like this:

```{r}
proportions(table(communities$disadvantage))
```

--

We can pipe them like this:

```{r}
communities |> pull(disadvantage) |> table() |> proportions()
```

--

Read this as, "take `communities`, and then pull out the `incarceration` column, and then make a `table()`, and then calculate `proportions()`."


---
# Creating Columns

`incarceration` looks like an ordinal variable (`disadvantage` too) but R doesn't know this—it just puts them in alphabetical order

--

To fix this, we need to know how to create or modify variables in our data

--

`dplyr` uses the `mutate()` function to create or modify variables:

```{r}
communities |>
  mutate(high_crime = crime_rate > mean(crime_rate)) |>
  head(4)
```

This created a **logical** (`TRUE`/`FALSE`) variable because we used a logical expression

---
# Modifying Columns

In R, we "modify" objects—including columns in our data—by replacing them with new versions

--

We saw before that our disadvantage and incarceration variables are ordinal but not being recognized that way

--

We can give them a proper order by making them **factors** and specifying their **levels**

```{r}
communities <- communities |> #<<
  mutate(disadvantage = 
           factor(disadvantage, levels = c("Low", "Medium", "High")), #<<
         incarceration = 
           factor(incarceration, levels = c("Low", "Medium", "High"))
         )
```

To modify the original dataset, we just assign back to it—overwriting it with our changes!

---
# Fixed!

```{r}
communities |> pull(disadvantage) |> table()
```


```{r}
communities |> pull(incarceration) |> table()
```

--

.text-center[
*We'll create and modify variables more another day, but for now let's look at subsetting again*
]

---

# `filter()` Data Frames

```{r}
communities |> filter(incarceration == "High") |> head()
```

.text-center[
*What is this doing?*
]

--

`filter()` is a `{dplyr}` function for indexing dataframe **rows**

--

It takes *only* logical vectors (the result of **expressions**) as an argument

---
# Multiple Conditions

.pull-left[

### And: `&`

```{r, eval=FALSE}
communities |>
  filter(disadvantage == "Low" & 
         crime_rate > 40)
```

![:width 100%](img/disadvantage_and_crime.svg)

]

--

.pull-right[

### Or: `|`

```{r, eval=FALSE}
communities |>
  filter(disadvantage == "Low" | 
         crime_rate > 40)
```


![:width 100%](img/disadvantage_or_crime.svg)
]

---
class: inverse

# Distributions

&nbsp;

### Numbers today (boo!)

&nbsp;

### Pictures next week (fun!)

---

# Tabulations

Let's look at tabulations first. They're useful for summarizing categorical data.

--

`count()` is a `{dplyr}` function for tabulating one or more columns

```{r}
communities |> count(incarceration)
```

--

```{r}
communities |> count(incarceration) |> mutate(proportion = n/sum(n))
```

---

# `{janitor}`

`{janitor}` is a data cleaning package, but it makes tabulations easier too

```{r, eval = FALSE}
install.packages("janitor")
```

```{r}
library(janitor)
```


```{r}
communities |> tabyl(incarceration)
```


--

.pull-right[
.footnote[
It comes in *really* handy for **cross-tabs**—we'll see them soon!
]
]

---
# `summarize()`

`{dplyr}`'s **`summarize()`** takes your column(s) of data and computes something using **every row**: 

* Calculate the mean
* Calculate the standard deviation
* Obtain a sample size
--

```{r}
communities |>
  summarize(mean_crime_rate = mean(crime_rate),
            sd_crime_rate = sd(crime_rate), 
            n = n())
```

--

You can use any function in `summarize()` that aggregates *multiple values* into a *single value* (like `sum()`, `median()`, or `max()`).


---
class: inverse

# Associations

&nbsp;

### Which are really about **joint distributions**

---

# Cross-Tabs

Let's look at cross-tabs first. They're used for associations between categorical variables.

--

This is where `{janitor}`'s `tabyl()` begins to shine:

--

```{r}
communities |> tabyl(disadvantage, incarceration)
```

--

```{r}
communities |> tabyl(disadvantage, incarceration) |>
  adorn_percentages() # converts to cell percentages #<<
```

---
count: false

# Fancy Cross-Tabs 1

We can assemble *fancy* tables bit-by-bit with `{janitor}`

```{r}
communities |> 
  tabyl(disadvantage, incarceration) # make table
```

---
count: false

# Fancy Cross-Tabs 2

Add row and column totals!

```{r}
communities |> 
  tabyl(disadvantage, incarceration) |> # make table
  adorn_totals(c("row", "col")) # add row/col totals
```

---
count: false

# Fancy Cross-Tabs 3

Turn cells into (row) percentages instead of counts

```{r}
communities |> 
  tabyl(disadvantage, incarceration) |> # make table
  adorn_totals(c("row", "col")) |> # add row/col totals
  adorn_percentages()# make cells percentages
```

---
count: false

# Fancy Cross-Tabs 4

Round those percentages to two decimal places!

```{r}
communities |> 
  tabyl(disadvantage, incarceration) |> # make table
  adorn_totals(c("row", "col")) |> # add row/col totals
  adorn_percentages() |> # make cells percentages
  adorn_pct_formatting(digits = 2) # round to 2 digits
```

---
count: false

# Fancy Cross-Tabs 5

Add counts back in parentheses!

```{r}
communities |> 
  tabyl(disadvantage, incarceration) |> # make table
  adorn_totals(c("row", "col")) |> # add row/col totals
  adorn_percentages() |> # make cells percentages
  adorn_pct_formatting(digits = 2) |> # round to 2 digits
  adorn_ns() # add counts in parentheses
```


---
count: false

# Fancy Cross-Tabs 6

Add column variable name!

```{r}
communities |> 
  tabyl(disadvantage, incarceration) |> # make table
  adorn_totals(c("row", "col")) |> # add row/col totals
  adorn_percentages() |> # make cells percentages
  adorn_pct_formatting(digits = 2) |> # round to 2 digits
  adorn_ns() |> # add counts in parentheses
  adorn_title() # add col variable name
```

Not bad! That's not far from paper ready!

---

# Grouped Measures

If we wanted to calculated means for different groups, one easy way is to just subset the data

--

.pull-left[
```{r}
communities |>
  filter(disadvantage=="High") |> #<<
  summarize(
   mean_crime = mean(crime_rate),
   sd_crime   = sd(crime_rate), 
   n          = n())
```
]

.pull-right[
```{r}
communities |>
  filter(disadvantage=="Low") |> #<<
  summarize(
   mean_crime = mean(crime_rate),
   sd_crime   = sd(crime_rate), 
   n          = n())
```
]

--

Imagine if you had many groups, though! There's a better way.

---
  
# `group_by()`


The special function `group_by()` changes how functions operate on the data, most importantly `summarize()`.

Functions after `group_by()` are computed *within each group* as defined by variables given, rather than over all rows at once.

Excel analogue: pivot tables

.image-50[![Pivot table](http://www.excel-easy.com/data-analysis/images/pivot-tables/two-dimensional-pivot-table.png)]

---
# `group_by()` example

```{r}
communities |>
  group_by(disadvantage) |> #<<
  summarize(mean_crime = mean(crime_rate),
            sd_crime = sd(crime_rate), 
            n = n())
```

Because we did `group_by()` with `disadvantage` then used `summarize()`, we get *one row per value of `disadvantage`*!

Each value of disadvantage is its own **group**!

---

# Correlations

Correlations are mathematically complicated but simple to code

```{r}
cor(communities$pop_density, communities$crime_rate)
```

--

Alternatively, you can use the `with()` command for a bit less typing

```{r}
with(communities, cor(pop_density, crime_rate))
```

--

These are a bit easier than `dplyr` if you just want one correlation

```{r}
communities |> summarize(R = cor(pop_density, crime_rate))
```

---

# Multiple Correlations

If you want to do correlations *within groups*, `{dplyr}` is king again

```{r}
communities |>
  group_by(disadvantage) |>
  summarize(R = cor(pop_density, crime_rate))
```

In this case, the correlation between `pop_density` and `crime_rate` is similar at all levels of disadvantage

---
class: inverse

# Wrap-Up
  
* Recommended reading for next week

   * Kaplan, chapters 10 is review of today's content
      * Chapter 14 (graphing) is what we'll get into next week
   * You're pretty busy, so make it low priority!

* `{swirl}` units if you want practice

   * 5 covers missing values
   * 6 covers subsetting

* Next time:

   * More on relationships
   * Distributions
   * Maybe a start on inference