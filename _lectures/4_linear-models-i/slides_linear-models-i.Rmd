---
title: "Linear Models I"
subtitle: "IQA Lecture 4"
author: "Charles Lanfear"
date: "2 Nov 2022<br>Updated: `r gsub(' 0', ' ', format(Sys.Date(), format='%d %b %Y'))`"
output:
  xaringan::moon_reader:
    css: "../assets/cam-css.css"
    lib_dir: libs
    nature:
      highlightStyle: tomorrow-night-bright
      highlightLines: true
      countIncrementalSlides: false
      beforeInit: "../assets/cam_macros.js"
      titleSlideClass: ["center","top"]
---

```{r setup, purl=FALSE}
#| include: false
options(width = 68)
knitr::opts_chunk$set(eval=TRUE, echo=TRUE, message=FALSE, warning=FALSE, dev = "svg", fig.height = 4)
```


# Things to include

Categorical predictors

* Binary
  * T-Test
* 3+ category
  * ANOVA

Controlling for variables

* Demeaning with dummies
* Residuals
* Partial correlations (is that pairs plot?)

How linear models work

* Simulating data
* Back doors
* Colliders



---

# Setup

Like usual, let's start by loading the communities data

First, let's convert our categorical variables to factors with appropriate levels

.text-85[
```{r, message = FALSE, warning = FALSE}
library(tidyverse)
library(broom) # Going to use this a bunch today
communities <- 
  read_csv("https://clanfear.github.io/ioc_iqa/_data/communities.csv") |>
  mutate(across(c(incarceration, disadvantage), 
                ~ factor(., levels = c("Low", "Medium", "High"))),
         area = factor(area, levels = c("Rural", "Urban")))
```
]

We can use `across()` as a shortcut to perform the same operation on multiple variables

--

This is the same as doing this:

.text-85[
```{r, eval = FALSE}
mutate(incarceration = 
         factor(incarceration, levels = c("Low", "Medium", "High")), 
       disadvantage = 
         factor(disadvantage, levels = c("Low", "Medium", "High")))
```
]

---

# Another `across()`

You can also give `across()` a list of functions and it will apply them to each variable

```{r}
communities |>
  group_by(incarceration) |>
  summarize(across(c(crime_rate, pop_density), 
                   list(mu = ~mean(.), 
                        sd = ~sd(.))))
```

This calculated a `mean()` and `sd()` each for `crime_rate` and `pop_density` within each level of `incarceration` with very little code!

---
class: inverse

# Linear Models

### Different predictors

---

# Continuous



.pull-left[
```{r}
lm(crime_rate ~ pop_density, 
   data = communities) |> 
  coef() # extract coefficients
```

We've seen a lot of linear models with continuous predictors

It is easy to visualize what the model is doing with a line laid over a scatterplot
]

.pull-right[
```{r, message = FALSE, warning = FALSE}
ggplot(communities, 
       aes(x = pop_density, 
           y = crime_rate)) + 
  geom_point() + 
  geom_smooth(method = "lm")
```
]




---

# Dummy Variables

What is a regression model doing when you have a binary predictor?

--



.pull-left[
```{r}
lm(crime_rate ~ area, 
   data = communities) |>
  coef()
```

The data look weird and `geom_smooth()` doesn't even do anything!

Why do the data look like this?
]

.pull-right[
```{r, message = FALSE, warning = FALSE}
ggplot(communities, 
       aes(x = area, 
           y = crime_rate)) + 
  geom_point() + 
  geom_smooth(method = "lm")
```
]





---

# A Slight Modification

.pull-left[
```{r}
lm(crime_rate ~ area, 
   data = communities) |>
  coef()
```

It turns out the linear model actually treats a binary variable as a numeric one that takes values of 0 or 1.

When `areaUrban` is 0 (`area` is `"Rural"`) the mean `crime_rate` is $10.43$

When `areaUrban` is 1 (`area` is `"Urban"`) the mean is $10.43 + 30.18 = 40.61$

]
.pull-right[
```{r, message = FALSE, warning = FALSE}
communities |> 
  mutate(urban = 
    as.numeric(area=="Urban")) |>
  ggplot(aes(x = urban, 
             y = crime_rate)) + 
  geom_point() + 
  geom_smooth(method = "lm")
```
]





---

# Mean Differences



.pull-left[
Linear regression is just estimating means by group!

```{r}
dummy_model <- 
  lm(crime_rate ~ area, 
     data = communities)
dummy_model |> coef()
```

The intercept is the average crime rate for rural places

The value for `areaUrban` is the **difference** between rural and urban places

]
.pull-right[
Compare the model to group-specific average crime rates:
```{r}
communities |>
  group_by(area) |>
  summarize(crime_rate = 
              mean(crime_rate))
```

$\text{Urban} = 40.61 = 10.43 + 30.18$

]

These are saying the exact same thing!


---

# Hypothesis Testing

Significance testing with dummy variables works like any others

.text-85[
```{r}
summary(dummy_model)$coefficients
```
]

--

This is *identical* to a two-sample t-test!

.text-85[
```{r}
t.test(crime_rate ~ area, data = communities, var.equal=TRUE)
```
]

.pull-right-40[
.footnote[
This is a significance test for a difference in group means—the same as our dummy variable model!
]
]

---

# More Categories

When a variable has more than two categories, all but one category is converted to a mutually exclusive binary variable

.pull-left[
```{r}
lm(crime_rate ~ incarceration, 
   data = communities) |> 
  tidy() |> 
  select(term, estimate)

```
]
.pull-right[
```{r}
communities |>
  group_by(incarceration) |>
  summarize(crime_rate = 
              mean(crime_rate))
```
]

Here our intercept represent the mean when `incarceration` is neither `"Medium"` nor `"High"`. Our **reference category** is `"Low"`

---

# ANOVA

Some of you may be familiar with ANOVA for analysing how 3+ category variables relate to a continuous outcome

.text-85[
```{r}
aov(crime_rate ~ incarceration, data = communities) |> summary()
```
]

--

Turns out ANOVA is just a standard linear model with a categorical variable

```{r}
aov(crime_rate ~ incarceration, data = communities) |> coef()
```

--

Until you get to very advanced methods (i.e., mixed effects models), ANOVA is just a less flexible linear model with more complicated terminology

---

# As an `lm()`

.text-85[
```{r}
summary(lm(crime_rate ~ incarceration, data = communities))
```
]

.footnote[
Note the F-statistic for the regression is the F value for the ANOVA
]

---
class: inverse

# Controls

&nbsp;

&nbsp;

![:width 50%](img/yoda.gif)

---

# Controlling for Variables

Remember that we control for variables for the purpose of **identifying** something we're interested in

--

In causal research, this is some **treatment effect**.

* In the following examples, we'll assume we want to identify $X \rightarrow Y$

--

In other cases, it may just be some association we're interested in.

--

To know if a control does what you want (e.g., closes a back door), it is important to understand:

* What including that control implies for your model
* Exactly what including it really does numerically



---

# Categorical Controls



We include a categorical control $Z$ if we believe some of $X$ and $Y$'s apparent relationship is due to *some $Z$ groups having different average levels of X and Y*

--

If we remove group-specific averages of both X and Y, we can get rid of that

--

.pull-left[
.text-85[
```{r}
lm(crime_rate ~ pop_density + area,
   data = communities) |> 
  tidy() |>
  select(term, estimate)
```
]

Note the identical `pop_density` slopes!
]
.pull-right[
.text-85[
```{r}
residualized_data <- communities |>
  group_by(area) |>
  mutate(pop_density_res =  #<<
      pop_density - mean(pop_density), #<<
         crime_rate_res  =  #<<
      crime_rate - mean(crime_rate)) #<<
lm(crime_rate_res ~ pop_density_res, #<<
   data = residualized_data)  |> 
  tidy() |> select(term, estimate)
```
]
]



---

# Visualising It

.pull-left[
```{r, message = FALSE}
ggplot(communities, 
       aes(x = pop_density, 
           y = crime_rate, 
           color = area)) + 
  geom_point() + 
  geom_smooth(method = "lm", 
              color = "black") 
```

]
.pull-right[
```{r, message = FALSE}
ggplot(residualized_data, 
       aes(x = pop_density_res, #<<
           y = crime_rate_res, #<<
           color = area))+ 
  geom_point() + 
  geom_smooth(method = "lm",
              color = "black")
```
]

Rural and urban data points now occupy a similar area due to subtracting their average $X$ and $Y$ values—this gives us their **residuals**

---

# Residuals

Residuals are the difference between model predictions and the actual data

.text-85[
```{r}
lm_res <- lm(crime_rate ~ pop_density, data = communities) |> augment()
```
]

.pull-left[
.text-85[
```{r}
ggplot(lm_res, 
    aes(x = pop_density, 
        y = crime_rate)) + 
  geom_point() + 
  geom_smooth(method = "lm")
```
]
]
.pull-right[
.text-85[
```{r}
ggplot(lm_res,
    aes(x = pop_density, 
        y = .resid)) +  #<<
  geom_point() + 
  geom_smooth(method = "lm")
```
]
]

--

.text-center[
The residuals are what our model *doesn't explain*
]

---

# `car::avPlot()`

This type of plot is sometimes called an **added variable plot**

.pull-left[
```{r, message = FALSE}
ggplot(residualized_data, 
       aes(x = pop_density_res,
           y = crime_rate_res))+ 
  geom_point() + 
  geom_smooth(method = "lm")
```
]

--

.pull-right[
```{r}
lm(crime_rate ~ pop_density + 
   area, 
   data = communities) |> 
  car::avPlot(
    variable = "pop_density")
```
]

These show the regression line *controlling for all other included variables*—and unlike `ggplot2`, `avPlot()` can accept more variables at once

---

# Continuous Variables

We include continuous controls if some of X and Y's relationship is because Z makes X and Y higher/lower—sometimes called **spuriousness**

--

If we remove variation in X and Y due to Z, we can fix this

--

Here we use bivariate models predicting what we want to residualise

.text-85[
```{r}
residualized_data <- communities %>%
  mutate(area_num       = as.numeric(area == "Urban"),
         crime_rate_res = residuals(lm(crime_rate ~ pop_density, data = .)), #<<
         area_res       = residuals(lm(area_num ~ pop_density, data = .))) #<<
```
]

--

.pull-left[
.text-85[
```{r}
lm(crime_rate ~ pop_density + area, 
   data = communities) |> 
  tidy() |> select(term, estimate)
```

]
]

.pull-right[
.text-85[
```{r}
lm(crime_rate_res ~ area_res, #<<
   data = residualized_data) |> #<<
  tidy() |> select(term, estimate)
```

]
]


---

# Visualising It

.pull-left[

Original data:

```{r, message = FALSE}
ggplot(residualized_data, 
       aes(x = area_num, 
           y = crime_rate, 
           color = area)) + 
  geom_point() + 
  geom_smooth(method = "lm", 
              color = "black") 
```

]
.pull-right[
Residuals of $X$ and $Y$:

```{r, message = FALSE}
ggplot(residualized_data, 
       aes(x = area_res, #<<
           y = crime_rate_res, #<<
           color = area))+ 
  geom_point() + 
  geom_smooth(method = "lm",
              color = "black")
```
]

--

.text-center[
*Wait, wat? I thought it was binary?*
]

---

# wat

Yep, that's not a mistake—our model predicted *how urban* each point was and the residual is the *unexpected level of urban* on a 0 to 1 scale—weird!

.pull-left[
```{r, message = FALSE}
ggplot(residualized_data, 
       aes(x = area_res, #<<
           y = crime_rate_res, #<<
           color = area))+ 
  geom_point() + 
  geom_smooth(method = "lm",
              color = "black")
```
]

.pull-right[
```{r}
lm(crime_rate ~ pop_density + 
       area, 
   data = communities) |> 
    car::avPlot(
        variable = "areaUrban")
```

]

---
class: inverse

# How It Works

&nbsp;

![:width 80%](img/trebuchet.jpg)

---

# Generating Data

If you don't like doing mathematical proofs to figure out if something works, you can often test things with simulation

--

`rnorm()` and similar functions randomly generate data *drawn* from a particular distribution


.pull-left[

```{r}
sample_size <- 10000
sim_data <- 
  tibble(bd =
    rnorm(sample_size, #<<
          mean = 3, sd = 1)) #<<
sim_data |>
  summarize(bd_mean = mean(bd), 
            bd_sd   = sd(bd))
```
]

--

.pull-right[
```{r}
ggplot(sim_data, 
       aes(x = bd)) +
  geom_density()
```
]

---

# Simulation

Now we can add other variables to our data to generate a dataset that obeys the DAG on the right

.pull-left-60[
.text-85[
```{r}
sim_data <- sim_data |>
  mutate(
    x = rnorm(n(), 0.3*bd, 1),
    y = rnorm(n(), 3 + 0.3*x + 0.3*bd, 1), #<<
    coll = rnorm(n(), -0.2*x + -0.2*y, 1))
```


]
]

.pull-right-40[
```{tikz sim-dag, fig.width = 2.75, cache = TRUE, purl = FALSE, echo = FALSE}
\usetikzlibrary{positioning}
\definecolor{black}{HTML}{000000}
\tikzset{
    > = stealth,
    every node/.append style = {
        draw = none,
        scale = 3
    },
    every path/.append style = {
        arrows = ->,
        draw = black,
        fill = none,
        scale = 1,
        line width = 1.5mm
    },
    hidden/.style = {
        draw = black,
        shape = circle,
        inner sep = 1pt
    }
}
\tikz{
  \node (Y) at (0,5) {$Y$};
  \node (X) at (5, 0) {$X$};
  \node (B) at (5, 5) {$BD$};
  \node (C) at (0, 0) {$COLL$};
  \path (X) edge (Y);
  \path (B) edge (Y);
  \path (B) edge (X);
  \path (X) edge (C);
  \path (Y) edge (C);
  }
```
]

--

"Y is equal to 3 plus 0.3 X and 0.3 BD, with about 1 SD of error on average"

--

Note that we generate the variables in causal order of the diagram

* We started with `bd`
* We finished with `coll`

---

# Estimates with Back Doors

Because we know the **data generating process**—we created it—we know what our estimates should be

--

.pull-left[
```{r}
lm(y ~ x + bd, #<<
   data = sim_data) |>
  tidy() |> 
  select(term, estimate)
```
]

--

.pull-right[
```{r}
lm(y ~ x , #<<
   data = sim_data) |>
  tidy() |> 
  select(term, estimate)
```
]

Excluding `bd` makes the effect of `x` larger than it should be—they're **magnified**

--

This occurs whenever a back door has effects with the *same sign* on both $X$ and $Y$ (e.g., both positive)—opposite signs would **attenuate** the estimate

---

# Estimates with Colliders

Again, we know what effects should be identified and how to identify them. What if we add the collider?

.pull-left[
```{r}
lm(y ~ x + bd, #<<
   data = sim_data) |>
  tidy() |> 
  select(term, estimate)
```
]

--

.pull-right[
```{r}
lm(y ~ x + bd + coll, #<<
   data = sim_data) |>
  tidy() |> 
  select(term, estimate)
```
]

This **attenuates** $X$ but does nothing to $BD$—it isn't a collider for $BD$!

.text-center[
*Let's look at a more severe example*
]


---

# Selection (Collider) Bias

Let's create the data from CRM yesterday.





```{r, fig.height = 3.5}
coll_data <- tibble(Skill     = runif(1000, 0, 10), 
                  Frequency = runif(1000, 0, 10), 
                  Who =   c(rep("Arrested", 500), 
                            rep("Everyone", 500))) |>
  filter(Who == "Everyone" | (10 + (-1*Skill) + Frequency > 10))

```

What's going on here?

* It is actually *two* sets of data in one: 
  * A pool of "everyone" and a pool of only "arrested" people
* *No relationship* between Skill at crime and Frequency of crime
* Skilled or infrequent offenders don't get arrested
  * i.e., we remove arrested people with high Skills or low Frequency

--

If we only see arrested people, we've *selected* on a collider—this is just like including one in a model


---

# Collider Model

.pull-left[
```{r}
lm(Frequency ~ Skill, #<<
   data = coll_data |> 
     filter(Who=="Everyone")) |>
  tidy() |> 
  select(term, estimate)
```
]

--

.pull-right[
```{r}
lm(Frequency ~ Skill, #<<
   data = coll_data |> 
     filter(Who=="Arrested")) |>
  tidy() |> 
  select(term, estimate)
```
]

--


We know there is no real relationship, but because we **selected** data based on an outcome of Frequency and Skill, it creates a **spurious** relationship

--

.text-center[
*The collider is still producing bias without being explicitly in the model!*
]


---

# Visualizing Collider Bias

```{r coll-plot, fig.height = 3.5}
ggplot(coll_data, aes(x = Skill, y = Frequency, color = Who)) + 
  facet_wrap(~Who) + geom_point() +
  geom_smooth(method = "lm", color = "black") +
  labs(x = "Skill at Crime", y = "Frequency of Crime") +
  theme_minimal(base_size = 16) + theme(legend.position = "none")
```

---
class: inverse

# Randomization



---

# Non-Randomized Treatment

Let's create example data with actual **potential outcomes**

```{r}
sample_size <- 10000
po_data <- tibble(
  bd = runif(sample_size, 0, 1), # Random uniform variable
  x  = rbinom(sample_size, 1, bd), # Random binary variable
  y0 = rnorm(sample_size, 2*bd, 1),
  y1 = rnorm(sample_size, 2*bd + 1, 1)) |> # Effect size of 1 #<<
  mutate(y = ifelse(x==1, y1, y0)) # Treatment just selects outcome
```


* `x` is a binary **treatment** with effect size of **1**
* `y0` is the outcome if the unit is **untreated**
* `y1` is the outcome if the unit is **treated**
* `bd` is a backdoor predicting treatment *and* `y`
   * `bd` improves both potential outcomes *the same* amount
   * `bd` also makes treatment more likely

.text-center[
*Units that get treated tend to have higher potential outcomes*
]

---

# Estimation

Like usual, if we can *see* the back door, we can identify the effect of $X$ on $Y$

.pull-left[
```{r}
lm(y ~ x + bd, data = po_data) |>
  tidy() |> 
  select(term, estimate)
```
]
.pull-right[
```{r}
lm(y ~ x, data = po_data) |>
  tidy() |> 
  select(term, estimate)
```
]

--

.text-center[
*But even if we can't, we can randomize it away*
]

--

`sample()` is an easy way to randomly select units

```{r}
sample(0:1, 20, replace= TRUE)
```

---

# Random Assignment

Let's select random units to receive the treatment

```{r}
po_data <- po_data |>
  mutate(treat = sample(0:1, n(), replace=TRUE),
         yt = ifelse(treat==1, y1, y0))
```

All the treatment does is determine which potential outcome we see

--

.pull-left[
```{r}
lm(y ~ x + bd, data = po_data) |>
  tidy() |> 
  select(term, estimate)
```
]
.pull-right[
```{r}
lm(yt ~ treat, data = po_data) |>
  tidy() |> 
  select(term, estimate)
```
]

.text-center[
*Randomization closes back doors without adjustment!*
]

---

# Wrap-Up

Assignment:

* Posted tomorrow morning:
  * On website in units (both week 4 and 5)
  * On Moodle
* Read instructions carefully
   * No trick questions intended
* Doc types:
  * Word or equivalent + .R script file for code
     * Use comments to indicate question code applies to
  * Quarto / Rmarkdown if you're feeling fancy
* Due 11:59 PM Friday 11 November
  * **Do not spend that entire time working on it**

No reading until next week